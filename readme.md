# Local AI Chat

A private, fast, and local AI chat interface powered by Ollama.

## Features

-   Chat with any local Ollama model.
-   Saves your chat history locally.
-   Supports system prompts, personalities, and memories.
-   Simple, clean interface with dark and light modes.

## Download

You can download the latest version for Windows from the [**GitHub Releases page**](https://github.com/YOUR_USERNAME/YOUR_REPOSITORY_NAME/releases/latest).

## How to Run from Source (for Developers)

1.  Clone the repository:
    `git clone https://github.com/YOUR_USERNAME/YOUR_REPOSITORY_NAME.git`
2.  Create and activate a virtual environment.
3.  Install dependencies:
    `pip install -r requirements.txt`
    *(You will need to create a `requirements.txt` file first. See below.)*
4.  Run the application:
    `python app.py`

---

Built with Python, Flask, and Ollama.
