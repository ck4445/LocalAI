# prompt.md

Fix file uploads not reaching the model.

## Repo files

* `app.py` - Python backend that handles chat streaming, uploads, and calls the model.
* `index.html` - Frontend UI that sends chat text and manages uploads.

## Problem

Uploads are saved to disk but their contents never enter the model context. The chat streaming endpoint builds `messages` only from prior chat text and ignores `chat["attachments"]`.

## Goal

When a user uploads files, their text contents are injected into the model prompt automatically. No frontend change required. Non-text files are skipped safely.

## Tasks

1. Load attachment files for the active chat in `app.py`.
2. Read text content with robust encoding handling.
3. Concatenate into a single context block that lists each filename and content.
4. Inject that block into the first system message. If no system message exists, prepend one.
5. Enforce a simple size guard to avoid exceeding limits.
6. Leave `index.html` unchanged.

## Acceptance criteria

* Ask “what’s in this file” after upload returns the file text in the model reply.
* No server errors on binary or oversized files.
* Existing chat behavior unchanged when no files are attached.

## Implementation

Add a helper in `app.py`:

```python
from pathlib import Path
from typing import List, Dict, Any

ATTACH_CHAR_BUDGET = 120_000  # ~80–120k chars is a safe stand-in for ~20k tokens

def _attachments_dir(chat_id: str) -> Path:
    # existing helper already present; keep or adapt as needed
    return Path("data") / "attachments" / chat_id

def _load_attachment_blocks(chat: Dict[str, Any]) -> str:
    """
    Reads uploaded attachments for this chat and returns a single formatted string.
    Skips non-text files. Truncates to ATTACH_CHAR_BUDGET chars.
    """
    att_list = chat.get("attachments") or []
    if not att_list:
        return ""

    folder = _attachments_dir(chat["id"])
    blocks: List[str] = []
    used = 0

    for att in att_list:
        att_id = str(att.get("id", ""))
        name = att.get("name", "file")
        # Find the stored file with any extension that matches the id
        files = list(folder.glob(f"{att_id}.*"))
        if not files:
            continue
        p = files[0]
        try:
            text = p.read_text(encoding="utf-8")
        except UnicodeDecodeError:
            try:
                text = p.read_text(encoding="latin-1", errors="ignore")
            except Exception:
                text = ""

        if not text:
            blocks.append(f"File: {name}\n\n[unreadable or empty]")
            continue

        # Budget guard
        remaining = max(0, ATTACH_CHAR_BUDGET - used)
        if remaining == 0:
            break
        if len(text) > remaining:
            text = text[:remaining] + "\n\n[truncated]"
        used += len(text)

        blocks.append(f"File: {name}\n\n{text}")

    if not blocks:
        return ""

    return "Attached files:\n\n" + "\n\n----\n\n".join(blocks)
```

Inject into the chat stream in `app.py`:

```python
# Inside api_chat_stream (before sending to the model)

chat = get_chat(chat_id)  # existing
messages: List[Dict[str, str]] = list(chat.get("messages", []))

attach_block = _load_attachment_blocks(chat)
if attach_block:
    # Find an existing system message
    sys_idx = next((i for i, m in enumerate(messages) if m.get("role") == "system"), None)
    if sys_idx is not None:
        messages[sys_idx]["content"] = messages[sys_idx].get("content", "") + "\n\n" + attach_block
    else:
        messages.insert(0, {"role": "system", "content": attach_block})

# Continue with existing call to the model using `messages`
```

Notes:

* Do not change upload endpoints or `index.html`.
* If the code already builds a composite system prompt, merge `attach_block` into that string instead of inserting a new message.
* Keep current token limits. The character budget is a conservative proxy.

## Post-change checks

* Upload a small `.txt` then ask about it. The response should reference its content and filename.
* Upload a binary like `.png`. No crash. The system message lists it as unreadable.
* Upload a very large text. The system message shows `[truncated]`.
